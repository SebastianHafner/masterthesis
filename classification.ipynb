{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "path = f'data/'\n",
    "folder_composites = f'composites/'\n",
    "folder_coefficients = f'coefficients/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import itertools\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import datetime as dt\n",
    "import math\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import osr\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" //////////////////////// functions //////////////////////// \"\"\"\n",
    "\n",
    "# function to read in a data cube from a geo tiff file\n",
    "def geotiff_to_datacube(fname):\n",
    "    \n",
    "    ds = gdal.Open(fname)\n",
    "    \n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    \n",
    "    proj = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "    epsg = int(proj.GetAttrValue('AUTHORITY',1))\n",
    "    \n",
    "    xy_shape = np.array(ds.GetRasterBand(1).ReadAsArray()).shape\n",
    "    \n",
    "    # get number of bands in raster file\n",
    "    n_bands = ds.RasterCount\n",
    "    \n",
    "    # initialize a data cube\n",
    "    xyz_shape = xy_shape + (n_bands,)\n",
    "    data_cube = np.ndarray(xyz_shape)\n",
    "    \n",
    "    # fill it with bands\n",
    "    for i in range(1,n_bands+1):\n",
    "        data_cube[:,:,i-1] =  np.array(ds.GetRasterBand(i).ReadAsArray())\n",
    "    \n",
    "    return data_cube, geotransform, epsg\n",
    "    # end of read in datacube function\n",
    "    \n",
    "    \n",
    "def save_geotiff(data_cube,geotransform,epsg,fname):\n",
    "    \n",
    "    n_rows, n_cols = data_cube.shape[0:2]\n",
    "    n_bands = data_cube.shape[2] if len(data_cube.shape)>2 else 1\n",
    "    \n",
    "    # open geo tiff file\n",
    "    ds = gdal.GetDriverByName('GTiff').Create('placeholder.tif',n_cols, n_rows, n_bands, gdal.GDT_Float32)\n",
    "    ds.SetGeoTransform(geotransform)\n",
    "    \n",
    "    # set crs\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(epsg)\n",
    "    ds.SetProjection(srs.ExportToWkt())\n",
    "    \n",
    "    # write data cube to geo tiff\n",
    "    if n_bands==1:\n",
    "        ds.GetRasterBand(1).WriteArray(data_cube[:,:])\n",
    "    else:\n",
    "        for i_band in range(n_bands):\n",
    "            ds.GetRasterBand(i_band+1).WriteArray(data_cube[:,:,i_band])\n",
    "    \n",
    "    dst_ds = gdal.GetDriverByName('GTiff').CreateCopy(fname+'.tif', ds)\n",
    "    dst_ds = None\n",
    "    # end of save function\n",
    "    \n",
    "    \n",
    "    # function to plot a classified image  \n",
    "def plot(image_classified):\n",
    "     \n",
    "    # define class labels and colors\n",
    "    classes = [\n",
    "        'Artificial areas',\n",
    "        'Grass and herb vegetation',\n",
    "        'Brush vegetation', 'Tree vegetation',\n",
    "        'Bare land', 'Water',\n",
    "        'Glacier, perpetual snow'\n",
    "    ]\n",
    "    \n",
    "    hex_colors = [\n",
    "        \"#FF0000\",\n",
    "        \"#FFFF00\",\n",
    "        \"#B2B200\",\n",
    "        \"#00B200\",\n",
    "        \"#804D33\",\n",
    "        '#0000FF',\n",
    "        '#B2B2B2'\n",
    "    ]\n",
    "    \n",
    "    cmap = mpl.colors.ListedColormap(hex_colors)\n",
    "    norm = mpl.colors.BoundaryNorm(np.arange(-0.5,7), cmap.N)\n",
    "        \n",
    "    # plot map\n",
    "    fig, ax = plt.subplots(figsize=(10,10))        \n",
    "    im = ax.imshow(image_classified, cmap=cmap, norm=norm)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.new_horizontal(size=\"5%\", pad=0.4, pack_start=False)\n",
    "    fig.add_axes(cax)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation=\"vertical\", ticks=np.linspace(0,7,8))\n",
    "    cbar.ax.set_yticklabels(classes)\n",
    "    plt.show()\n",
    "    # end of plot function\n",
    "    \n",
    "      \n",
    "\n",
    "def train_validate_classifier(clf, train, test, features, label):\n",
    "        \n",
    "    # getting training and testing features\n",
    "    X_train = train[features]\n",
    "    X_test = test[features]\n",
    "    \n",
    "    # getting training and testing labels\n",
    "    y_train = train[label]\n",
    "    y_test = test[label]\n",
    "    \n",
    "    # training classifier\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train,y_train)\n",
    "    run_time = time.time() - start_time\n",
    "    \n",
    "    # creating error matrix for validation\n",
    "    y_pred = clf.predict(X_test)\n",
    "    error_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return error_matrix\n",
    "\n",
    "\n",
    "\n",
    "def apply_gaussian_kernel(data_kernel,gaussian_kernel):\n",
    "    \n",
    "    assert(data_kernel.shape==gaussian_kernel.shape)\n",
    "    \n",
    "    class_probabilities = {}\n",
    "    for index, prob in np.ndenumerate(gaussian_kernel):\n",
    "        class_ = int(data_kernel[index[0],index[1]])\n",
    "        class_prob = class_probabilities.get(class_,0)\n",
    "        class_probabilities[class_] = class_prob + prob\n",
    "    \n",
    "    new_class = max(class_probabilities, key=class_probabilities.get)\n",
    "    return new_class\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_filter(image,kernel_size):\n",
    "    \n",
    "    kernel5 = np.array([\n",
    "        [1,4,7,4,1],\n",
    "        [4,16,26,16,4],\n",
    "        [7,26,41,26,7],\n",
    "        [4,16,26,16,4],\n",
    "        [1,4,7,4,1]\n",
    "    ])\n",
    "\n",
    "    kernel3 = np.array([\n",
    "        [1,2,1],\n",
    "        [2,4,2],\n",
    "        [1,2,1]\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    gaussian_kernel = kernel3 if kernel_size==3 else kernel5 \n",
    "    offset = gaussian_kernel.shape[0]//2\n",
    "\n",
    "    new_image = np.copy(image)\n",
    "    \n",
    "    # loop over all pixels ignoring edges\n",
    "    for i in range(offset,image.shape[0]-offset):\n",
    "        for j in range(offset,image.shape[1]-offset):\n",
    "        \n",
    "        \n",
    "            data_kernel = image[i-offset:i+offset+1,j-offset:j+offset+1,0]\n",
    "            new_image[i,j,0] = apply_gaussian_kernel(data_kernel,gaussian_kernel)\n",
    "\n",
    "               \n",
    "    return new_image\n",
    "\n",
    "\n",
    "def validate_filtered(trained_clf,spatial,test,feature_image,label):\n",
    "    \n",
    "    y_test, y_pred = ([],[])\n",
    "    \n",
    "    for roi in rois:\n",
    "        \n",
    "        # subsetting test data to roi\n",
    "        test_roi = test[test['roi']==roi]\n",
    "        x_coords = list(test_roi['X'])\n",
    "        y_coords = list(test_roi['Y'])\n",
    "        labels = list(test_roi[label])\n",
    "        \n",
    "        # getting image data for roi\n",
    "        year = 2006 if roi=='roi2' else 2007\n",
    "        image, geotransform, epsg = geotiff_to_datacube(f'{feature_image}_{roi}_{year}.tif')\n",
    "        xOrigin = geotransform[0]\n",
    "        yOrigin = geotransform[3]\n",
    "        pixelWidth = geotransform[1]\n",
    "        pixelHeight = -geotransform[5]\n",
    "        \n",
    "        for i, (x_coord,y_coord,class_) in enumerate(zip(x_coords,y_coords,labels)):\n",
    "            \n",
    "            # computing column and row indices\n",
    "            icol = int((x_coord - xOrigin) / pixelWidth)\n",
    "            irow = int((yOrigin - y_coord ) / pixelHeight)\n",
    "\n",
    "            if not spatial:\n",
    "                \n",
    "                # create vector of pixels for classifier input\n",
    "                kernel = image[irow-1:irow+2,icol-1:icol+2,:]\n",
    "                feature_vector = kernel.reshape((3*3, kernel.shape[2]))\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # create vector of kernels for classifier input\n",
    "                feature_vector = []\n",
    "                for irowk in range(irow-1,irow+2):\n",
    "                    for icolk in range(icol-1,icol+2):\n",
    "                        kernel = image[irowk-1:irowk+2,icolk-1:icolk+2,:]\n",
    "                        kernel_flattened = kernel.flatten()\n",
    "                        feature_vector.append(kernel_flattened)\n",
    "                feature_vector = np.array(feature_vector)\n",
    "                if i ==0: print(feature_vector.shape)\n",
    "                                            \n",
    "            # classify pixel vector and reshape to image\n",
    "            predictions = trained_clf.predict(feature_vector)\n",
    "                \n",
    "            classified_kernel = predictions.reshape((3,3))\n",
    "        \n",
    "            class_pred = apply_gaussian_kernel(classified_kernel,gaussian_kernel3)\n",
    "            \n",
    "            y_test.append(class_)\n",
    "            y_pred.append(class_pred)\n",
    "                \n",
    "    \n",
    "    error_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # computing average user's and producer's accuracy\n",
    "    avg_uacc = compute_avg_uacc(error_matrix)\n",
    "    avg_pacc = compute_avg_pacc(error_matrix)\n",
    "    \n",
    "    return (avg_uacc, avg_pacc)\n",
    "\n",
    "\n",
    "\"\"\" //////////////////////// classes //////////////////////// \"\"\"\n",
    "\n",
    "# class to create a deep neural network (dnn). the dnn object is compatible with scikit-learn's\n",
    "# classifier, i.e. also provides the fit and predict methods.\n",
    "class DeepNeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trained = False\n",
    "        self.enc = OneHotEncoder(categories='auto')\n",
    "        self.model = False\n",
    "        \n",
    "        # end of init method\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        # one hot encoding data\n",
    "        y_train_onehot = np.asarray(y_train)\n",
    "        self.enc.fit(y_train_onehot.reshape(-1,1))\n",
    "        y_train_onehot = self.enc.transform(y_train_onehot.reshape(-1,1)).todense()\n",
    "        \n",
    "        # getting input and output dimension of data\n",
    "        input_dim = len(X_train.columns)\n",
    "        output_dim = y_train_onehot.shape[1]\n",
    "        \n",
    "        # setting up model\n",
    "        self.model = keras.Sequential([\n",
    "            keras.layers.Dense(200, input_dim=input_dim, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(100, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(50, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(output_dim, activation=tf.nn.softmax)\n",
    "        ])\n",
    "        opt = keras.optimizers.Adam(lr=0.001)\n",
    "        self.model.compile(\n",
    "          optimizer=opt,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics = [\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        # training deep neural network\n",
    "        batchsize = 48\n",
    "        for i in range(6):\n",
    "            self.model.fit(X_train, y_train_onehot, epochs=20, batch_size=batchsize, verbose=0)#, sample_weight=sample_weights.reshape(-1))\n",
    "            batchsize *= 2\n",
    "        \n",
    "        self.trained = True\n",
    "        # end of fit method\n",
    "        \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        if self.trained:\n",
    "            y_pred = np.argmax(self.model.predict(X_test), axis=1)\n",
    "        \n",
    "        return y_pred\n",
    "        # end of predict method\n",
    "\n",
    "        \n",
    "\n",
    "# class that provides methods to assess classification results by implementing various accuracy metrics.\n",
    "class ErrorMatrix:\n",
    "\n",
    "    \n",
    "    def __init__(self,matrix,labels=False):\n",
    "        \n",
    "        self.matrix = matrix\n",
    "        self.n_classes = matrix.shape[0]\n",
    "\n",
    "        self.labels = labels if labels else list(range(self.n_classes))\n",
    "        \n",
    "        \n",
    "    def column_total(self):\n",
    "        \n",
    "        return list(np.sum(self.matrix, axis=0))\n",
    "        \n",
    "    \n",
    "    def row_total(self):\n",
    "        \n",
    "        return list(np.sum(self.matrix, axis=1))\n",
    "    \n",
    "    \n",
    "    def total(self):\n",
    "        \n",
    "        return sum(self.column_total())\n",
    "        \n",
    "    \n",
    "    def users_accuracies(self):\n",
    "    \n",
    "        row_total = self.row_total()\n",
    "        uas = [self.matrix[i,i]/float(row_total[i])*100 for i in range(self.n_classes)]\n",
    "    \n",
    "        return uas\n",
    "\n",
    "    \n",
    "    def average_users_accuracy(self):\n",
    "        \n",
    "        return np.mean(self.users_accuracies())\n",
    "    \n",
    "    \n",
    "    def producers_accuracies(self):\n",
    "    \n",
    "        column_total = self.column_total()\n",
    "        pas = [self.matrix[i,i]/float(column_total[i])*100 for i in range(self.n_classes)]\n",
    "    \n",
    "        return pas\n",
    "    \n",
    "    \n",
    "    def average_producers_accuracy(self):\n",
    "        \n",
    "        return np.mean(self.producers_accuracies())\n",
    "    \n",
    "    \n",
    "    def overall_accuracy(self):\n",
    "        \n",
    "        correctly_classified = sum([self.matrix[i,i] for i in range(self.n_classes)])\n",
    "        total = sum(list(np.sum(self.matrix, axis=1)))\n",
    "        oa = correctly_classified/float(total)*100\n",
    "        \n",
    "        return oa\n",
    "    \n",
    "    \n",
    "    def average_accuracy(self):\n",
    "    \n",
    "        aa = np.mean(self.users_accuracies())\n",
    "    \n",
    "        return aa\n",
    "\n",
    "    \n",
    "    def mean_accuracy(self):\n",
    "    \n",
    "        ma = (self.average_accuracy()+self.overall_accuracy())/2.\n",
    "    \n",
    "        return ma\n",
    "    \n",
    "    \n",
    "    def kappa(self):\n",
    "        \n",
    "        # Cohen's kappa (Cohen, 1960; doi:10.1177/001316446002000104)\n",
    "        X_test, y_pred = ([],[])\n",
    "        for index, value in np.ndenumerate(self.matrix):\n",
    "            pred, label = index\n",
    "            X_test.extend([label for _ in range(value)])\n",
    "            y_pred.extend([pred for _ in range(value)])\n",
    "        \n",
    "        return cohen_kappa_score(X_test,y_pred)\n",
    "    \n",
    "    \n",
    "    def accuracy_metrics(self):\n",
    "        \n",
    "        ametrics = []\n",
    "        ametrics.append(('OA',self.overall_accuracy())\n",
    "        ametrics.append(('AvgUA',self.average_users_accuracy())\n",
    "        ametrics.append(('AvgPA',self.average_producers_accuracy())\n",
    "        ametrics.append(('AA',self.average_accuracy())\n",
    "        ametrics.append(('MA',self.mean_accuracy())\n",
    "        ametrics.append(('Kappa',self.kappa())\n",
    "        \n",
    "        return ametrics\n",
    "        \n",
    "        \n",
    "    def print_matrix(self):\n",
    "        \n",
    "        print(self.matrix)\n",
    "    \n",
    "    \n",
    "    def print_summary(self):\n",
    "        \n",
    "        print(f'Summary statistics (n Samples: {self.total()})')\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # overall statistics        \n",
    "        print(f'{self.overall_accuracy():.2f} % (OA)')\n",
    "        print(f'{self.average_users_accuracy():.2f} % (Average UA)')\n",
    "        print(f'{self.average_producers_accuracy():.2f} % (Average PA)')\n",
    "        print(f'{self.average_accuracy():.2f} % (AA = Average UA)')\n",
    "        print(f'{self.mean_accuracy():.2f} % (MA = (OA + AA)/2)')        \n",
    "        print(f'{self.kappa():.2f} (Kappa)')\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # class wise statistics\n",
    "        column_total = self.column_total()\n",
    "        row_total = self.row_total()\n",
    "        \n",
    "        uas = self.users_accuracies()\n",
    "        pas = self.producers_accuracies()\n",
    "        \n",
    "        for i, label in enumerate(self.labels):\n",
    "            print(f'{label}: {uas[i]:.2f} % (UA) n Class: {row_total[i]}; {pas[i]:.2f} % (PA) n Ref: {column_total[i]})')\n",
    "            \n",
    "\n",
    "    \n",
    "    def to_latex(self):\n",
    "        \n",
    "        return ''\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roi</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>land_cover</th>\n",
       "      <th>topleft_blue_c</th>\n",
       "      <th>topleft_blue_a1</th>\n",
       "      <th>topleft_blue_b1</th>\n",
       "      <th>topleft_green_c</th>\n",
       "      <th>topleft_green_a1</th>\n",
       "      <th>topleft_green_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>lowerright_red_b1</th>\n",
       "      <th>lowerright_nir_c</th>\n",
       "      <th>lowerright_nir_a1</th>\n",
       "      <th>lowerright_nir_b1</th>\n",
       "      <th>lowerright_swir1_c</th>\n",
       "      <th>lowerright_swir1_a1</th>\n",
       "      <th>lowerright_swir1_b1</th>\n",
       "      <th>lowerright_swir2_c</th>\n",
       "      <th>lowerright_swir2_a1</th>\n",
       "      <th>lowerright_swir2_b1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roi1</td>\n",
       "      <td>667600</td>\n",
       "      <td>252600</td>\n",
       "      <td>2</td>\n",
       "      <td>380.638367</td>\n",
       "      <td>65.649033</td>\n",
       "      <td>38.340347</td>\n",
       "      <td>504.429260</td>\n",
       "      <td>-17.511360</td>\n",
       "      <td>105.570168</td>\n",
       "      <td>...</td>\n",
       "      <td>71.432404</td>\n",
       "      <td>2337.309326</td>\n",
       "      <td>-1329.805420</td>\n",
       "      <td>-254.358856</td>\n",
       "      <td>1125.302246</td>\n",
       "      <td>-367.617249</td>\n",
       "      <td>-0.383392</td>\n",
       "      <td>516.211548</td>\n",
       "      <td>-87.554733</td>\n",
       "      <td>66.352211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roi1</td>\n",
       "      <td>667700</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>332.687958</td>\n",
       "      <td>32.793858</td>\n",
       "      <td>59.761925</td>\n",
       "      <td>421.774048</td>\n",
       "      <td>-45.964584</td>\n",
       "      <td>97.390305</td>\n",
       "      <td>...</td>\n",
       "      <td>64.486885</td>\n",
       "      <td>2031.968262</td>\n",
       "      <td>-1501.842651</td>\n",
       "      <td>-55.873653</td>\n",
       "      <td>966.418213</td>\n",
       "      <td>-525.751587</td>\n",
       "      <td>82.470558</td>\n",
       "      <td>459.251709</td>\n",
       "      <td>-175.961182</td>\n",
       "      <td>91.420761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roi1</td>\n",
       "      <td>667800</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>306.430084</td>\n",
       "      <td>20.838465</td>\n",
       "      <td>31.285831</td>\n",
       "      <td>387.130463</td>\n",
       "      <td>-60.250031</td>\n",
       "      <td>60.218811</td>\n",
       "      <td>...</td>\n",
       "      <td>71.439423</td>\n",
       "      <td>1651.890991</td>\n",
       "      <td>-594.699707</td>\n",
       "      <td>22.281591</td>\n",
       "      <td>659.893311</td>\n",
       "      <td>-279.609406</td>\n",
       "      <td>61.193287</td>\n",
       "      <td>286.992676</td>\n",
       "      <td>-129.099976</td>\n",
       "      <td>49.272015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roi1</td>\n",
       "      <td>667900</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>289.838318</td>\n",
       "      <td>2.063600</td>\n",
       "      <td>22.950096</td>\n",
       "      <td>367.620850</td>\n",
       "      <td>-66.887375</td>\n",
       "      <td>54.132072</td>\n",
       "      <td>...</td>\n",
       "      <td>90.105492</td>\n",
       "      <td>1693.013306</td>\n",
       "      <td>-506.476105</td>\n",
       "      <td>67.894760</td>\n",
       "      <td>635.475464</td>\n",
       "      <td>-265.514648</td>\n",
       "      <td>125.416039</td>\n",
       "      <td>281.357941</td>\n",
       "      <td>-138.290726</td>\n",
       "      <td>83.930519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roi1</td>\n",
       "      <td>668000</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>301.951447</td>\n",
       "      <td>-8.857222</td>\n",
       "      <td>25.563393</td>\n",
       "      <td>398.568115</td>\n",
       "      <td>-87.492523</td>\n",
       "      <td>52.679016</td>\n",
       "      <td>...</td>\n",
       "      <td>67.915154</td>\n",
       "      <td>1584.583008</td>\n",
       "      <td>-763.324524</td>\n",
       "      <td>120.866425</td>\n",
       "      <td>741.023560</td>\n",
       "      <td>-299.501282</td>\n",
       "      <td>168.571472</td>\n",
       "      <td>344.163757</td>\n",
       "      <td>-136.045792</td>\n",
       "      <td>104.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    roi       X       Y  land_cover  topleft_blue_c  topleft_blue_a1  \\\n",
       "0  roi1  667600  252600           2      380.638367        65.649033   \n",
       "1  roi1  667700  252600           3      332.687958        32.793858   \n",
       "2  roi1  667800  252600           3      306.430084        20.838465   \n",
       "3  roi1  667900  252600           3      289.838318         2.063600   \n",
       "4  roi1  668000  252600           3      301.951447        -8.857222   \n",
       "\n",
       "   topleft_blue_b1  topleft_green_c  topleft_green_a1  topleft_green_b1  ...  \\\n",
       "0        38.340347       504.429260        -17.511360        105.570168  ...   \n",
       "1        59.761925       421.774048        -45.964584         97.390305  ...   \n",
       "2        31.285831       387.130463        -60.250031         60.218811  ...   \n",
       "3        22.950096       367.620850        -66.887375         54.132072  ...   \n",
       "4        25.563393       398.568115        -87.492523         52.679016  ...   \n",
       "\n",
       "   lowerright_red_b1  lowerright_nir_c  lowerright_nir_a1  lowerright_nir_b1  \\\n",
       "0          71.432404       2337.309326       -1329.805420        -254.358856   \n",
       "1          64.486885       2031.968262       -1501.842651         -55.873653   \n",
       "2          71.439423       1651.890991        -594.699707          22.281591   \n",
       "3          90.105492       1693.013306        -506.476105          67.894760   \n",
       "4          67.915154       1584.583008        -763.324524         120.866425   \n",
       "\n",
       "   lowerright_swir1_c  lowerright_swir1_a1  lowerright_swir1_b1  \\\n",
       "0         1125.302246          -367.617249            -0.383392   \n",
       "1          966.418213          -525.751587            82.470558   \n",
       "2          659.893311          -279.609406            61.193287   \n",
       "3          635.475464          -265.514648           125.416039   \n",
       "4          741.023560          -299.501282           168.571472   \n",
       "\n",
       "   lowerright_swir2_c  lowerright_swir2_a1  lowerright_swir2_b1  \n",
       "0          516.211548           -87.554733            66.352211  \n",
       "1          459.251709          -175.961182            91.420761  \n",
       "2          286.992676          -129.099976            49.272015  \n",
       "3          281.357941          -138.290726            83.930519  \n",
       "4          344.163757          -136.045792           104.747475  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coefs = pd.read_csv(f'{path}labeled_data.csv')\n",
    "data_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>land_cover</th>\n",
       "      <th>adj</th>\n",
       "      <th>roi</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>nir</th>\n",
       "      <th>swir1</th>\n",
       "      <th>swir2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667600</td>\n",
       "      <td>252600</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>roi1</td>\n",
       "      <td>212.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>667700</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>roi1</td>\n",
       "      <td>208.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>667800</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>roi1</td>\n",
       "      <td>205.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>667900</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>roi1</td>\n",
       "      <td>203.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>668000</td>\n",
       "      <td>252600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>roi1</td>\n",
       "      <td>212.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X       Y  land_cover  adj   roi   blue  green    red     nir  swir1  \\\n",
       "0  667600  252600           2    1  roi1  212.0  304.0  208.0   979.0  751.0   \n",
       "1  667700  252600           3    7  roi1  208.0  325.0  213.0  1392.0  850.0   \n",
       "2  667800  252600           3    8  roi1  205.0  215.0  196.0   970.0  312.0   \n",
       "3  667900  252600           3    7  roi1  203.0  321.0  193.0  1329.0  445.0   \n",
       "4  668000  252600           3    7  roi1  212.0  309.0  218.0  1224.0  588.0   \n",
       "\n",
       "   swir2  \n",
       "0  361.0  \n",
       "1  465.0  \n",
       "2  153.0  \n",
       "3  216.0  \n",
       "4  312.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_acomp = pd.read_csv(f'{path}annual_composite_labeled.csv')\n",
    "data_acomp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scomp = pd.read_csv(f'{path}seasonal_composite_labeled.csv')\n",
    "data_scomp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/5\n",
      "Composite method (c) rf\n",
      "0.701 (Average user's accuracy)\n",
      "0.774 (Average producer's accuracy)\n",
      "Time series method (t) rf\n",
      "0.727 (Average user's accuracy)\n",
      "0.785 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) rf\n",
      "0.734 (Average user's accuracy)\n",
      "0.809 (Average producer's accuracy)\n",
      "Time series spatial method (ts) rf\n",
      "0.733 (Average user's accuracy)\n",
      "0.813 (Average producer's accuracy)\n",
      "Composite method (c) svm\n",
      "0.730 (Average user's accuracy)\n",
      "0.672 (Average producer's accuracy)\n",
      "Time series method (t) svm\n",
      "0.771 (Average user's accuracy)\n",
      "0.715 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) svm\n",
      "0.778 (Average user's accuracy)\n",
      "0.725 (Average producer's accuracy)\n",
      "Time series spatial method (ts) svm\n",
      "0.782 (Average user's accuracy)\n",
      "0.738 (Average producer's accuracy)\n",
      "Composite method (c) dnn\n",
      "0.632 (Average user's accuracy)\n",
      "0.715 (Average producer's accuracy)\n",
      "Time series method (t) dnn\n",
      "0.709 (Average user's accuracy)\n",
      "0.744 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) dnn\n",
      "0.724 (Average user's accuracy)\n",
      "0.770 (Average producer's accuracy)\n",
      "Time series spatial method (ts) dnn\n",
      "0.660 (Average user's accuracy)\n",
      "0.682 (Average producer's accuracy)\n",
      "Iteration: 2/5\n",
      "Composite method (c) rf\n",
      "0.705 (Average user's accuracy)\n",
      "0.776 (Average producer's accuracy)\n",
      "Time series method (t) rf\n",
      "0.729 (Average user's accuracy)\n",
      "0.790 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) rf\n",
      "0.739 (Average user's accuracy)\n",
      "0.810 (Average producer's accuracy)\n",
      "Time series spatial method (ts) rf\n",
      "0.730 (Average user's accuracy)\n",
      "0.810 (Average producer's accuracy)\n",
      "Composite method (c) svm\n",
      "0.733 (Average user's accuracy)\n",
      "0.673 (Average producer's accuracy)\n",
      "Time series method (t) svm\n",
      "0.772 (Average user's accuracy)\n",
      "0.715 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) svm\n",
      "0.780 (Average user's accuracy)\n",
      "0.726 (Average producer's accuracy)\n",
      "Time series spatial method (ts) svm\n",
      "0.783 (Average user's accuracy)\n",
      "0.741 (Average producer's accuracy)\n",
      "Composite method (c) dnn\n",
      "0.645 (Average user's accuracy)\n",
      "0.698 (Average producer's accuracy)\n",
      "Time series method (t) dnn\n",
      "0.718 (Average user's accuracy)\n",
      "0.746 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) dnn\n",
      "0.730 (Average user's accuracy)\n",
      "0.771 (Average producer's accuracy)\n",
      "Time series spatial method (ts) dnn\n",
      "0.662 (Average user's accuracy)\n",
      "0.688 (Average producer's accuracy)\n",
      "Iteration: 3/5\n",
      "Composite method (c) rf\n",
      "0.706 (Average user's accuracy)\n",
      "0.771 (Average producer's accuracy)\n",
      "Time series method (t) rf\n",
      "0.734 (Average user's accuracy)\n",
      "0.793 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) rf\n",
      "0.739 (Average user's accuracy)\n",
      "0.812 (Average producer's accuracy)\n",
      "Time series spatial method (ts) rf\n",
      "0.736 (Average user's accuracy)\n",
      "0.816 (Average producer's accuracy)\n",
      "Composite method (c) svm\n",
      "0.730 (Average user's accuracy)\n",
      "0.671 (Average producer's accuracy)\n",
      "Time series method (t) svm\n",
      "0.773 (Average user's accuracy)\n",
      "0.712 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) svm\n",
      "0.779 (Average user's accuracy)\n",
      "0.722 (Average producer's accuracy)\n",
      "Time series spatial method (ts) svm\n",
      "0.783 (Average user's accuracy)\n",
      "0.737 (Average producer's accuracy)\n",
      "Composite method (c) dnn\n",
      "0.647 (Average user's accuracy)\n",
      "0.729 (Average producer's accuracy)\n",
      "Time series method (t) dnn\n",
      "0.708 (Average user's accuracy)\n",
      "0.746 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) dnn\n",
      "0.719 (Average user's accuracy)\n",
      "0.774 (Average producer's accuracy)\n",
      "Time series spatial method (ts) dnn\n",
      "0.675 (Average user's accuracy)\n",
      "0.708 (Average producer's accuracy)\n",
      "Iteration: 4/5\n",
      "Composite method (c) rf\n",
      "0.708 (Average user's accuracy)\n",
      "0.778 (Average producer's accuracy)\n",
      "Time series method (t) rf\n",
      "0.728 (Average user's accuracy)\n",
      "0.788 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) rf\n",
      "0.740 (Average user's accuracy)\n",
      "0.813 (Average producer's accuracy)\n",
      "Time series spatial method (ts) rf\n",
      "0.736 (Average user's accuracy)\n",
      "0.815 (Average producer's accuracy)\n",
      "Composite method (c) svm\n",
      "0.736 (Average user's accuracy)\n",
      "0.675 (Average producer's accuracy)\n",
      "Time series method (t) svm\n",
      "0.775 (Average user's accuracy)\n",
      "0.719 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) svm\n",
      "0.783 (Average user's accuracy)\n",
      "0.728 (Average producer's accuracy)\n",
      "Time series spatial method (ts) svm\n",
      "0.785 (Average user's accuracy)\n",
      "0.742 (Average producer's accuracy)\n",
      "Composite method (c) dnn\n",
      "0.633 (Average user's accuracy)\n",
      "0.712 (Average producer's accuracy)\n",
      "Time series method (t) dnn\n",
      "0.701 (Average user's accuracy)\n",
      "0.746 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) dnn\n",
      "0.716 (Average user's accuracy)\n",
      "0.777 (Average producer's accuracy)\n",
      "Time series spatial method (ts) dnn\n",
      "0.671 (Average user's accuracy)\n",
      "0.709 (Average producer's accuracy)\n",
      "Iteration: 5/5\n",
      "Composite method (c) rf\n",
      "0.709 (Average user's accuracy)\n",
      "0.778 (Average producer's accuracy)\n",
      "Time series method (t) rf\n",
      "0.738 (Average user's accuracy)\n",
      "0.788 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) rf\n",
      "0.741 (Average user's accuracy)\n",
      "0.807 (Average producer's accuracy)\n",
      "Time series spatial method (ts) rf\n",
      "0.735 (Average user's accuracy)\n",
      "0.813 (Average producer's accuracy)\n",
      "Composite method (c) svm\n",
      "0.735 (Average user's accuracy)\n",
      "0.672 (Average producer's accuracy)\n",
      "Time series method (t) svm\n",
      "0.775 (Average user's accuracy)\n",
      "0.715 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) svm\n",
      "0.782 (Average user's accuracy)\n",
      "0.725 (Average producer's accuracy)\n",
      "Time series spatial method (ts) svm\n",
      "0.785 (Average user's accuracy)\n",
      "0.738 (Average producer's accuracy)\n",
      "Composite method (c) dnn\n",
      "0.638 (Average user's accuracy)\n",
      "0.717 (Average producer's accuracy)\n",
      "Time series method (t) dnn\n",
      "0.713 (Average user's accuracy)\n",
      "0.741 (Average producer's accuracy)\n",
      "Time series gaussian filtered method (t-gf) dnn\n",
      "0.728 (Average user's accuracy)\n",
      "0.768 (Average producer's accuracy)\n",
      "Time series spatial method (ts) dnn\n",
      "0.626 (Average user's accuracy)\n",
      "0.682 (Average producer's accuracy)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>method</th>\n",
       "      <th>users</th>\n",
       "      <th>producers</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>c</td>\n",
       "      <td>0.700589</td>\n",
       "      <td>0.773661</td>\n",
       "      <td>10.395797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>t</td>\n",
       "      <td>0.726582</td>\n",
       "      <td>0.784815</td>\n",
       "      <td>27.717604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>t-gf</td>\n",
       "      <td>0.733971</td>\n",
       "      <td>0.808759</td>\n",
       "      <td>27.717604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>ts</td>\n",
       "      <td>0.732922</td>\n",
       "      <td>0.813234</td>\n",
       "      <td>99.434160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>c</td>\n",
       "      <td>0.730330</td>\n",
       "      <td>0.671548</td>\n",
       "      <td>96.290816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier method     users  producers    runtime\n",
       "0         rf      c  0.700589   0.773661  10.395797\n",
       "1         rf      t  0.726582   0.784815  27.717604\n",
       "2         rf   t-gf  0.733971   0.808759  27.717604\n",
       "3         rf     ts  0.732922   0.813234  99.434160\n",
       "4        svm      c  0.730330   0.671548  96.290816"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois = ['roi1','roi2','roi3']\n",
    "\n",
    "\n",
    "label = 'land_cover'\n",
    "\n",
    "# define features\n",
    "bands = ['blue','green','red','nir','swir1','swir2']\n",
    "seasons = ['spring','summer','autumn']\n",
    "coefficients = ['c','a1','b1']\n",
    "positions = ['topleft','topcenter','topright','midleft','midcenter','midright','lowerleft','lowercenter','lowerright']\n",
    "\n",
    "features_ac = bands\n",
    "features_sc = [f'{band}_{season}' for band in bands for season in seasons]\n",
    "features_t = [f'midcenter_{band}_{coef}' for band in bands for coef in coefficients]\n",
    "features_ts = [f'{pos}_{band}_{coef}' for pos in positions for band in bands for coef in coefficients]\n",
    "\n",
    "# define filter used for gaussian filtering\n",
    "gaussian_kernel3 = np.array([\n",
    "    [1,2,1],\n",
    "    [2,4,2],\n",
    "    [1,2,1]\n",
    "])\n",
    "\n",
    "# define classifiers\n",
    "classifiers = {}\n",
    "classifiers['rf'] = RandomForestClassifier(n_estimators=100,class_weight='balanced')\n",
    "classifiers['svm'] = svm.SVC(gamma='scale', decision_function_shape='ovo', class_weight='balanced')\n",
    "classifiers['dnn'] = DeepNeuralNetwork()\n",
    "\n",
    "\n",
    "# data container\n",
    "data = []\n",
    "\n",
    "# define number of iterations\n",
    "n_iterations = 5\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    print(f'Iteration: {i+1}/{n_iterations}')\n",
    "    \n",
    "    # splitting data (using a different split for each iteration)\n",
    "    train_comp, test_comp = train_test_split(data_comp, test_size=0.3)\n",
    "    train_coefs, test_coefs = train_test_split(data_coefs, test_size=0.3)\n",
    "        \n",
    "    for clf_key in classifiers.keys():\n",
    "\n",
    "        clf  = classifiers[clf_key]\n",
    "        \n",
    "        # c (composite)\n",
    "        error_matrix_c = train_validate_classifier(clf,train_comp,test_comp,features_c,label)\n",
    "        error_matrix_c = ErrorMatrix(error_matrix_c)\n",
    "        \n",
    "        \n",
    "        print_accuracies(f'Composite method (c) {clf_key}', stats_c[0], stats_c[1])\n",
    "        data.append((clf_key,'c',*stats_c))\n",
    "        \n",
    "        # t (time series)\n",
    "        stats_t = train_validate_classifier(clf,train_coefs,test_coefs,features_t,label)\n",
    "        print_accuracies(f'Time series method (t) {clf_key}', stats_t[0], stats_t[1])\n",
    "        data.append((clf_key,'t',*stats_t))\n",
    "        \n",
    "        # ts (time series-spatial)\n",
    "        stats_ts = train_validate_classifier(clf,train_coefs,test_coefs,features_ts,label)\n",
    "        print_accuracies(f'Time series spatial method (ts) {clf_key}', stats_ts[0], stats_ts[1])\n",
    "        data.append((clf_key,'ts',*stats_ts))\n",
    "        \n",
    "        \"\"\"\n",
    "        # t-gf (time series gaussian filtered)\n",
    "        stats_tgf = validate_filtered(clf,False,test_coefs,f'{folder_coefficients}coefficients',label)\n",
    "        print_accuracies(f'Time series gaussian filtered method (t-gf) {clf_key}', stats_tgf[0], stats_tgf[1])\n",
    "        data.append((clf_key,'t-gf',*stats_tgf,stats_t[2]))\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        # ts-gf (time series-spatial gaussian filtered)\n",
    "        stats_tsgf = validate_filtered(clf,True,test_coefs,f'{folder_coefficients}coefficients',label)\n",
    "        print_accuracies(f'Time series spatial gaussian filtered method (ts-gf) {clf_key}', stats_tsgf[0], stats_tsgf[1])\n",
    "        data.append((clf_key,'ts-gf',*stats_tsgf,stats_ts[2]))\n",
    "        \"\"\"\n",
    "        \n",
    "d = {\n",
    "    'classifier': [entry[0] for entry in data],\n",
    "    'method': [entry[1] for entry in data],\n",
    "    'users': [entry[2] for entry in data],\n",
    "    'producers': [entry[3] for entry in data],\n",
    "    'runtime': [entry[4] for entry in data]\n",
    "}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv(f'{path}classification_data.csv', encoding='utf-8', index=False)\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label = 'land_cover'\n",
    "\n",
    "# define features\n",
    "bands = ['blue','green','red','nir','swir1','swir2']\n",
    "coefficients = ['c','a1','b1']\n",
    "positions = ['topleft','topcenter','topright','midleft','midcenter','midright','lowerleft','lowercenter','lowerright']\n",
    "\n",
    "features_c = bands\n",
    "features_t = [f'midcenter_{band}_{coef}' for band in bands for coef in coefficients]\n",
    "features_ts = [f'{pos}_{band}_{coef}' for pos in positions for band in bands for coef in coefficients]\n",
    "\n",
    "\n",
    "  \n",
    "# splitting data (using a different split for each iteration)\n",
    "train_comp, test_comp = train_test_split(data_comp, test_size=0.3)\n",
    "train_coefs, test_coefs = train_test_split(data_coefs, test_size=0.3)\n",
    " \n",
    "    \n",
    "    \n",
    "# getting training and testing features\n",
    "X_train = train_comp[features_c]\n",
    "X_test = test_comp[features_c]\n",
    "    \n",
    "# getting training and testing labels\n",
    "y_train = train_comp[label]\n",
    "y_test = test_comp[label]\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "y_train_onehot=np.asarray(y_train)\n",
    "enc.fit(y_train_onehot.reshape(-1,1))\n",
    "y_train_onehot = enc.transform(y_train_onehot.reshape(-1,1)).todense()\n",
    "\n",
    "\n",
    "#not too sure about these weights\n",
    "y_unique, y_where, num = np.unique(y_train_onehot, return_inverse=True, return_counts=True, axis=0)\n",
    "print(y_unique.shape)\n",
    "print(y_where.shape)\n",
    "print(y_where)\n",
    "class_weights_tmp = np.sum(num)/num\n",
    "sample_weights = np.empty((y_train_onehot.shape[0], 1))\n",
    "for i in range(y_unique.shape[0]):\n",
    "    sample_weights[np.argwhere(y_where==i)]=class_weights_tmp[i]\n",
    "print(sample_weights.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trained = False\n",
    "        self.enc = OneHotEncoder()\n",
    "        self.model = False\n",
    "        \n",
    "        # end of init method\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        # one hot encoding data\n",
    "        y_train_onehot = np.asarray(y_train)\n",
    "        self.enc.fit(y_train_onehot.reshape(-1,1))\n",
    "        y_train_onehot = self.enc.transform(y_train_onehot.reshape(-1,1)).todense()\n",
    "        \n",
    "        print(y_train_onehot.shape)\n",
    "        \n",
    "        # getting input and output dimension of data\n",
    "        input_dim = len(X_train.columns)\n",
    "        output_dim = y_train_onehot.shape[1]\n",
    "        \n",
    "        # setting up model\n",
    "        self.model = keras.Sequential([\n",
    "            keras.layers.Dense(200, input_dim=input_dim, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(100, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(50, activation=tf.nn.tanh),\n",
    "            keras.layers.Dense(output_dim, activation=tf.nn.softmax)\n",
    "        ])\n",
    "        opt = keras.optimizers.Adam(lr=0.001)\n",
    "        self.model.compile(\n",
    "          optimizer=opt,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics = [\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "        batchsize = 48\n",
    "        for i in range(6):\n",
    "            self.model.fit(X_train, y_train_onehot, epochs=20, batch_size=batchsize, verbose=0)#, sample_weight=sample_weights.reshape(-1))\n",
    "            batchsize *= 2\n",
    "        \n",
    "        self.trained = True\n",
    "        # end of fit method\n",
    "        \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        if self.trained:\n",
    "            y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "        \n",
    "        return y_pred\n",
    "        # end of predict method\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DeepNeuralNetwork()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "correct_pts_test = pred_test==y_test\n",
    "print(\"Correct labeled test points [%]: \", 100*np.sum(correct_pts_test)/y_test.shape[0])\n",
    "    \n",
    "pred_train = np.argmax(model.predict(X_train), axis=1)\n",
    "correct_pts_train = pred_train==y_train\n",
    "print(\"Correct labeled training points [%]: \", 100*np.sum(correct_pts_train)/y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" //////////////////////// neural network //////////////////////// \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(y_train_onehot.shape)\n",
    "print(X_train.shape)\n",
    "# define neural network, compile it and train the network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(200, input_dim=6, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(100, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(50, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(7, activation=tf.nn.softmax)\n",
    "])\n",
    "opt=keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(\n",
    "  optimizer=opt,\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "batchsize = 48\n",
    "for i in range(6):\n",
    "    model.fit(X_train, y_train_onehot, epochs=20, batch_size = batchsize,verbose=0)#, sample_weight=sample_weights.reshape(-1))\n",
    "    batchsize *= 2\n",
    "\n",
    "\n",
    "\n",
    "# validating for each region of interest\n",
    "\n",
    "        \n",
    "y_test=np.asarray(y_test)\n",
    "y_test_onehot = enc.transform(y_test.reshape(-1,1))\n",
    "print(y_test_onehot.shape)\n",
    "        \n",
    "# apply classifier to test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "    \n",
    "pred_test = np.argmax(model.predict(X_test), axis=1)\n",
    "correct_pts_test = pred_test==y_test\n",
    "print(\"Correct labeled test points [%]: \", 100*np.sum(correct_pts_test)/y_test.shape[0])\n",
    "    \n",
    "pred_train = np.argmax(model.predict(X_train), axis=1)\n",
    "correct_pts_train = pred_train==y_train\n",
    "print(\"Correct labeled training points [%]: \", 100*np.sum(correct_pts_train)/y_train.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics (n Samples: 100)\n",
      "\n",
      "74.00 % (OA)\n",
      "54.98 % (Average UA)\n",
      "53.75 % (Average PA)\n",
      "54.98 % (AA = Average UA)\n",
      "64.49 % (MA = (OA + AA)/2)\n",
      "0.08 (Kappa)\n",
      "\n",
      "0: 81.40 % (UA) n Class: 86; 87.50 % (PA) n Ref: 80)\n",
      "1: 28.57 % (UA) n Class: 14; 20.00 % (PA) n Ref: 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "error_matrix = np.array([\n",
    "    [70,16],\n",
    "    [10,4]\n",
    "])\n",
    "\n",
    "def users_accuracies(error_matrix):\n",
    "    \n",
    "    n = error_matrix.shape[0]\n",
    "    row_total = np.sum(error_matrix, axis=1)\n",
    "    uas = [error_matrix[i,i]/float(row_total[i]) for i in range(n)]\n",
    "    \n",
    "    return uas\n",
    "\n",
    "def producers_accuracies(error_matrix):\n",
    "    \n",
    "    n = error_matrix.shape[0]\n",
    "    column_total = np.sum(error_matrix, axis=0)\n",
    "    pas = [error_matrix[i,i]/float(column_total[i]) for i in range(n)]\n",
    "    \n",
    "    return pas\n",
    "\n",
    "def overall_accuracy(error_matrix):\n",
    "    \n",
    "    n = error_matrix.shape[0]\n",
    "    correctly_classified = sum([error_matrix[i,i] for i in range(n)])\n",
    "    total = sum(list(np.sum(error_matrix, axis=1)))\n",
    "    oa = correctly_classified/float(total)\n",
    "    \n",
    "    return oa\n",
    "\n",
    "def average_accuracy(error_matrix):\n",
    "    \n",
    "    aa = np.mean(users_accuracies(error_matrix))\n",
    "    \n",
    "    return aa\n",
    "\n",
    "def mean_accuracy(error_matrix):\n",
    "    \n",
    "    ma = (average_accuracy(error_matrix)+overall_accuracy(error_matrix))/2.\n",
    "    \n",
    "    return ma\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "users_accuracies(error_matrix)\n",
    "producers_accuracies(error_matrix)\n",
    "overall_accuracy(error_matrix)\n",
    "average_accuracy(error_matrix)\n",
    "mean_accuracy(error_matrix)\n",
    "\n",
    "\n",
    "class error_matrix:\n",
    "    \n",
    "    \n",
    "    def __init__(self,matrix,labels=False):\n",
    "        \n",
    "        self.matrix = matrix\n",
    "        self.n_classes = matrix.shape[0]\n",
    "\n",
    "        self.labels = labels if labels else list(range(self.n_classes))\n",
    "        \n",
    "        \n",
    "    def column_total(self):\n",
    "        \n",
    "        return list(np.sum(self.matrix, axis=0))\n",
    "        \n",
    "    \n",
    "    def row_total(self):\n",
    "        \n",
    "        return list(np.sum(self.matrix, axis=1))\n",
    "    \n",
    "    \n",
    "    def total(self):\n",
    "        \n",
    "        return sum(self.column_total())\n",
    "        \n",
    "    \n",
    "    def users_accuracies(self):\n",
    "    \n",
    "        row_total = self.row_total()\n",
    "        uas = [self.matrix[i,i]/float(row_total[i])*100 for i in range(self.n_classes)]\n",
    "    \n",
    "        return uas\n",
    "\n",
    "    \n",
    "    def average_users_accuracy(self):\n",
    "        \n",
    "        return np.mean(self.users_accuracies())\n",
    "    \n",
    "    \n",
    "    def producers_accuracies(self):\n",
    "    \n",
    "        column_total = self.column_total()\n",
    "        pas = [self.matrix[i,i]/float(column_total[i])*100 for i in range(self.n_classes)]\n",
    "    \n",
    "        return pas\n",
    "    \n",
    "    \n",
    "    def average_producers_accuracy(self):\n",
    "        \n",
    "        return np.mean(self.producers_accuracies())\n",
    "    \n",
    "    \n",
    "    def overall_accuracy(self):\n",
    "        \n",
    "        correctly_classified = sum([self.matrix[i,i] for i in range(self.n_classes)])\n",
    "        total = sum(list(np.sum(self.matrix, axis=1)))\n",
    "        oa = correctly_classified/float(total)*100\n",
    "        \n",
    "        return oa\n",
    "    \n",
    "    \n",
    "    def average_accuracy(self):\n",
    "    \n",
    "        aa = np.mean(self.users_accuracies())\n",
    "    \n",
    "        return aa\n",
    "\n",
    "    \n",
    "    def mean_accuracy(self):\n",
    "    \n",
    "        ma = (self.average_accuracy()+self.overall_accuracy())/2.\n",
    "    \n",
    "        return ma\n",
    "    \n",
    "    \n",
    "    def kappa(self):\n",
    "        \n",
    "        # Cohen's kappa (Cohen, 1960; doi:10.1177/001316446002000104)\n",
    "        X_test, y_pred = ([],[])\n",
    "        for index, value in np.ndenumerate(self.matrix):\n",
    "            pred, label = index\n",
    "            X_test.extend([label for _ in range(value)])\n",
    "            y_pred.extend([pred for _ in range(value)])\n",
    "        \n",
    "        return cohen_kappa_score(X_test,y_pred)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def print_matrix(self):\n",
    "        \n",
    "        print(self.matrix)\n",
    "    \n",
    "    \n",
    "    def print_summary(self):\n",
    "        \n",
    "        print(f'Summary statistics (n Samples: {self.total()})')\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # overall statistics        \n",
    "        print(f'{self.overall_accuracy():.2f} % (OA)')\n",
    "        print(f'{self.average_users_accuracy():.2f} % (Average UA)')\n",
    "        print(f'{self.average_producers_accuracy():.2f} % (Average PA)')\n",
    "        print(f'{self.average_accuracy():.2f} % (AA = Average UA)')\n",
    "        print(f'{self.mean_accuracy():.2f} % (MA = (OA + AA)/2)')        \n",
    "        print(f'{self.kappa():.2f} (Kappa)')\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # class wise statistics\n",
    "        column_total = self.column_total()\n",
    "        row_total = self.row_total()\n",
    "        \n",
    "        uas = self.users_accuracies()\n",
    "        pas = self.producers_accuracies()\n",
    "        \n",
    "        for i, label in enumerate(self.labels):\n",
    "            print(f'{label}: {uas[i]:.2f} % (UA) n Class: {row_total[i]}; {pas[i]:.2f} % (PA) n Ref: {column_total[i]})')\n",
    "            \n",
    "\n",
    "    \n",
    "    def to_latex(self):\n",
    "        \n",
    "        return ''\n",
    "\n",
    "    \n",
    "a = np.array([[70,16],[10,4]])\n",
    "b = np.array([[70,0],[0,4]])    \n",
    "test = error_matrix(a)\n",
    "test.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
