{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import osr\n",
    "from IPython.display import display, clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# function to read in a data cube from a geo tiff file\n",
    "def geotiff_to_datacube(fname):\n",
    "    \n",
    "    ds = gdal.Open(fname)\n",
    "    \n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    \n",
    "    proj = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "    epsg = int(proj.GetAttrValue('AUTHORITY',1))\n",
    "    \n",
    "    xy_shape = np.array(ds.GetRasterBand(1).ReadAsArray()).shape\n",
    "    \n",
    "    # get number of bands in raster file\n",
    "    n_bands = ds.RasterCount\n",
    "    \n",
    "    # initialize a data cube\n",
    "    xyz_shape = xy_shape + (n_bands,)\n",
    "    data_cube = np.ndarray(xyz_shape)\n",
    "    \n",
    "    # fill it with bands\n",
    "    for i in range(1,n_bands+1):\n",
    "        data_cube[:,:,i-1] =  np.array(ds.GetRasterBand(i).ReadAsArray())\n",
    "    \n",
    "    return data_cube, geotransform, epsg\n",
    "    # end of read in datacube function\n",
    "\n",
    "\n",
    "# global variables\n",
    "rois = ['roi1','roi2','roi3']\n",
    "\n",
    "folder_as = f'arealstatistik/'\n",
    "folder_coefficients = f'data/coefficients/'\n",
    "folder_composites = f'data/composites/'\n",
    "folder_output = f'data/classification_data/'\n",
    "\n",
    "spectral_bands = ['blue','green','red','nir','swir1','swir2']\n",
    "\n",
    "yearAS = 2004 # 2004 or 2013\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label coefficients\n",
    "\n",
    "# creating name of features\n",
    "coefficients = ['c','a1','b1']\n",
    "\n",
    "kernelv = ['top','mid','lower']\n",
    "kernelh = ['left','center','right']\n",
    "positions = [f'{v}{h}' for v in kernelv for h in kernelh]\n",
    "\n",
    "feature_names = [f'{pos}_{band}_{coef}' for pos in positions for band in spectral_bands for coef in coefficients]\n",
    "\n",
    "# initializing containers\n",
    "x_coords, y_coords, land_covers = ([],[],[])\n",
    "datasets = []\n",
    "\n",
    "\n",
    "for roi in rois:\n",
    "    \n",
    "    print(roi)\n",
    "    \n",
    "    # year of data acquisition\n",
    "    if yearAS == 2004:\n",
    "        year = 2006 if roi=='roi2' else 2007\n",
    "    elif yearAS == 2013:\n",
    "        year = 2015 if roi=='roi2' else 2016\n",
    "    \n",
    "    # loading arealstatistik\n",
    "    df = pd.read_csv(f'{folder_as}{roi}_as{yearAS}_preprocessed.csv')\n",
    "    nrows = df.shape[0]\n",
    "\n",
    "    # loading coefficients\n",
    "    dc_coefficients, geotransform, epsg = geotiff_to_datacube(f'{folder_coefficients}coefficients_{roi}_{year}.tif')\n",
    "\n",
    "    # using lists and dictionary to avoid slow iteration with pd data frame\n",
    "    x_list = list(df['X']); x_coords.extend(x_list)\n",
    "    y_list = list(df['Y']); y_coords.extend(y_list)\n",
    "    lc_list = list(df['land_cover']); land_covers.extend(lc_list)\n",
    "    \n",
    "    features = np.zeros((nrows,len(feature_names)))\n",
    "\n",
    "    # unpack geotranform\n",
    "    xOrigin = geotransform[0]\n",
    "    yOrigin = geotransform[3]\n",
    "    pixelWidth = geotransform[1]\n",
    "    pixelHeight = -geotransform[5]\n",
    "    \n",
    "    for i, (x_coord,y_coord) in enumerate(zip(x_list,y_list)):\n",
    "    \n",
    "\n",
    "        # computing column and row indices\n",
    "        icol = int((x_coord - xOrigin) / pixelWidth)\n",
    "        irow = int((yOrigin - y_coord ) / pixelHeight)\n",
    "    \n",
    "        kernel = dc_coefficients[irow-1:irow+2,icol-1:icol+2,:]\n",
    "        features[i,:] = kernel.flatten()\n",
    "        \n",
    "    dataset = pd.DataFrame(data=features,columns=feature_names)\n",
    "    dataset['roi'] = roi\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "\n",
    "data = pd.concat(datasets,axis=0)\n",
    "data['X'] = x_coords\n",
    "data['Y'] = y_coords\n",
    "data['land_cover'] = land_covers\n",
    "\n",
    "# rearrange columns\n",
    "data = data[['roi','X','Y','land_cover',*feature_names]]\n",
    "\n",
    "data.to_csv(f'{folder_output}coefficients_labeled_as{yearAS}.csv', encoding='utf-8', index=False)\n",
    "data.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label annual composites\n",
    "\n",
    "# creating name of features\n",
    "feature_names = spectral_bands\n",
    "\n",
    "# initializing containers\n",
    "x_coords, y_coords, land_covers = ([],[],[])\n",
    "datasets = []\n",
    "\n",
    "for roi in rois:\n",
    "    \n",
    "    print(roi)\n",
    "    \n",
    "    # year of data acquisition\n",
    "    if yearAS == 2004:\n",
    "        year = 2006 if roi=='roi2' else 2007\n",
    "    elif yearAS == 2013:\n",
    "        year = 2015 if roi=='roi2' else 2016\n",
    "    \n",
    "    # loading arealstatistik\n",
    "    df = pd.read_csv(f'{folder_as}{roi}_as{yearAS}_preprocessed.csv')\n",
    "    nrows = df.shape[0]\n",
    "\n",
    "    # loading coefficients\n",
    "    dc_composite, geotransform, epsg = geotiff_to_datacube(f'{folder_composites}annual_composite_{roi}_{year}.tif')\n",
    "\n",
    "    # using lists and dictionary to avoid slow iteration with pd data frame\n",
    "    x_list = list(df['X']); x_coords.extend(x_list)\n",
    "    y_list = list(df['Y']); y_coords.extend(y_list)\n",
    "    lc_list = list(df['land_cover']); land_covers.extend(lc_list)\n",
    "    \n",
    "    features = np.zeros((nrows,len(feature_names)))\n",
    "\n",
    "    # unpack geotranform\n",
    "    xOrigin = geotransform[0]\n",
    "    yOrigin = geotransform[3]\n",
    "    pixelWidth = geotransform[1]\n",
    "    pixelHeight = -geotransform[5]\n",
    "    \n",
    "    for i, (x_coord,y_coord) in enumerate(zip(x_list,y_list)):\n",
    "    \n",
    "        # computing column and row indices\n",
    "        icol = int((x_coord - xOrigin) / pixelWidth)\n",
    "        irow = int((yOrigin - y_coord ) / pixelHeight)\n",
    "    \n",
    "        features[i,:] = dc_composite[irow,icol,:]\n",
    "\n",
    "        \n",
    "    dataset = pd.DataFrame(data=features,columns=feature_names)\n",
    "    dataset['roi'] = roi\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "\n",
    "data = pd.concat(datasets,axis=0)\n",
    "data['X'] = x_coords\n",
    "data['Y'] = y_coords\n",
    "data['land_cover'] = land_covers\n",
    "\n",
    "# rearrange columns\n",
    "data = data[['roi','X','Y','land_cover',*feature_names]]\n",
    "\n",
    "data.to_csv(f'{folder_output}annual_composite_labeled_as{yearAS}.csv', encoding='utf-8', index=False)\n",
    "data.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# label annual composites\n",
    "\n",
    "# creating name of features\n",
    "seasons = ['spring','summer','autumn']\n",
    "feature_names = [f'{band}_{season}' for pos in positions for band in spectral_bands]\n",
    "\n",
    "# initializing containers\n",
    "x_coords, y_coords, land_covers = ([],[],[])\n",
    "datasets = []\n",
    "\n",
    "\n",
    "for roi in rois:\n",
    "    \n",
    "    print(roi)\n",
    "    \n",
    "    # year of data acquisition\n",
    "    if yearAS == 2004:\n",
    "        year = 2006 if roi=='roi2' else 2007\n",
    "    elif yearAS == 2013:\n",
    "        year = 2015 if roi=='roi2' else 2016\n",
    "    \n",
    "    # loading arealstatistik\n",
    "    df = pd.read_csv(f'{data_folder_as}{roi}_as{yearAS}_preprocessed.csv')\n",
    "    nrows = df.shape[0]\n",
    "\n",
    "    # loading coefficients\n",
    "    dc_spring, geotransform, epsg = geotiff_to_datacube(f'{folder_composites}seasonal_composite_spring_{roi}_{year}.tif')\n",
    "    dc_summer, _, _ = geotiff_to_datacube(f'{folder_composites}seasonal_composite_summer_{roi}_{year}.tif')\n",
    "    dc_autumn, _, _ = geotiff_to_datacube(f'{folder_composites}seasonal_composite_autumn_{roi}_{year}.tif')\n",
    "\n",
    "    # using lists and dictionary to avoid slow iteration with pd data frame\n",
    "    x_list = list(df['X']); x_coords.extend(x_list)\n",
    "    y_list = list(df['Y']); y_coords.extend(y_list)\n",
    "    lc_list = list(df['land_cover']); land_covers.extend(lc_list)\n",
    "    \n",
    "    features = np.zeros((nrows,len(feature_names)))\n",
    "\n",
    "    # unpack geotranform\n",
    "    xOrigin = geotransform[0]\n",
    "    yOrigin = geotransform[3]\n",
    "    pixelWidth = geotransform[1]\n",
    "    pixelHeight = -geotransform[5]\n",
    "    \n",
    "    for i, (x_coord,y_coord) in enumerate(zip(x_list,y_list)):\n",
    "    \n",
    "        # computing column and row indices\n",
    "        icol = int((x_coord - xOrigin) / pixelWidth)\n",
    "        irow = int((yOrigin - y_coord ) / pixelHeight)\n",
    "    \n",
    "        features[i,:] = dc_composite[irow,icol,:]\n",
    "\n",
    "    dataset = pd.DataFrame(data=features,columns=feature_names)\n",
    "    dataset['roi'] = roi\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "data = pd.concat(datasets,axis=0)\n",
    "data['X'] = x_coords\n",
    "data['Y'] = y_coords\n",
    "data['land_cover'] = land_covers\n",
    "\n",
    "# rearrange columns\n",
    "data = data[['roi','X','Y','land_cover',*feature_names]]\n",
    "\n",
    "data.to_csv(f'{folder_output}seasonal_composite_labeled_as{yearAS}.csv', encoding='utf-8', index=False)\n",
    "data.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
